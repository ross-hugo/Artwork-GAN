{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ross-hugo/Artwork-GAN/blob/main/Discriminator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S4fsyVSiWYF0",
    "outputId": "a9aec0f2-bad2-42f1-d292-891125c8dc87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Artwork-GAN' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/ross-hugo/Artwork-GAN/\n",
    "cd Artwork-GAN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rosscopeland/Desktop/school/Machine_Learning_738/projects/Artwork-GAN'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, GlobalAveragePooling1D, LeakyReLU, UpSampling2D, Conv2D\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "from src.generator import Generator\n",
    "from src.discriminator import Discriminator\n",
    "from src.sgan import SGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xBmiqZVwtZwq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x10fd08850>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan = SGAN(verbosity=False)\n",
    "gan.discriminator.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'discriminator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3fe8cf8e175b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/school/Machine_Learning_738/projects/Artwork-GAN/src/sgan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, X, y)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m#train discriminator on real images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhalf_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;31m#train discriminator on fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhalf_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'discriminator' is not defined"
     ]
    }
   ],
   "source": [
    "gan.train(epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "dir = \"images/\"\n",
    "train_ds = image_dataset_from_directory(dir,\n",
    "  validation_split=0.2, subset=\"training\",\n",
    "  seed=123,\n",
    "  labels=\"inferred\",label_mode=\"int\"\n",
    "  ,image_size=(128, 128), color_mode= \"rgb\")\n",
    "val_ds = image_dataset_from_directory(dir,\n",
    "  validation_split=0.2, subset=\"validation\",\n",
    "  seed=123,\n",
    "  labels=\"inferred\",label_mode=\"int\"\n",
    "  ,image_size=(128, 128), color_mode= \"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "      ax = plt.subplot(3, 3, i + 1)\n",
    "      plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "      plt.title(int(labels[i]))\n",
    "      plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#losses: rotation loss & hinge loss (for the true versus fake prediction)\n",
    "#penalties (such as the gradient penalty)\n",
    "#normalization techniques: self-modulated batch normalization which doesnt require labels\n",
    "#neural architecture: ResNet\n",
    "#evaluation metrics: FID score\n",
    "#ResNet contains 6 blocks\n",
    "#I'm assuming that we will have a GAN class and inside that class we'll have the discriminator and generator functions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vC-Fvo3htXll"
   },
   "outputs": [],
   "source": [
    "#discriminator would use a resnet architecture\n",
    "#how to build a resnet as a discriminator\n",
    "#what are the parameters that they've used for the ResNet?\n",
    "#will start here by building the resnet\n",
    "#--------> I'll continue working in the discriminator.py file\n",
    "\n",
    "###anna's sudo code pls ignore\n",
    "#for epoch in range(num_epoch):\n",
    "   #train model\n",
    "   #for each id in ... the dataset\n",
    "      #first \"optimize\"\n",
    "      #image = \"image\"\n",
    "      #representation = model(image)\n",
    "      # #calculate loss\n",
    "      # optimize \n",
    "\n",
    "from keras.datasets import mnist \n",
    "# from discriminator import Discriminator\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "D = Discriminator()\n",
    "model = D.define_model()\n",
    "\n",
    "\n",
    "\n",
    "def rotate_img(img, rot):\n",
    "  if rot == 0:  # 0 degrees rotation\n",
    "    return img\n",
    "  elif rot == 90:\n",
    "    return np.rot90(img,k=1, axes=(1,2))\n",
    "  elif rot == 180:\n",
    "    return np.rot90(img,k=2, axes=(1,2))\n",
    "  elif rot == 270:\n",
    "    return np.rot90(img,k=3, axes=(1,2))\n",
    "  else:\n",
    "    raise ValueError(\"rotation not valid\")\n",
    "  # elif rot == 90:  # 90 degrees rotation\n",
    "  #     return np.flipud(np.transpose(img, (1, 0, 2)))\n",
    "  # elif rot == 180:  # 90 degrees rotation\n",
    "  #     return np.fliplr(np.flipud(img))\n",
    "  # elif rot == 270:  # 270 degrees rotation / or -90\n",
    "  #     return np.transpose(np.flipud(img), (1, 0, 2))\n",
    "  # elif rot == 120:\n",
    "  #     return ndimage.rotate(img, 120, reshape=False)\n",
    "  # elif rot == 240:\n",
    "  #     return ndimage.rotate(img, 240, reshape=False)\n",
    "  # else:\n",
    "  #     raise ValueError('rotation error')\n",
    "\n",
    "def train_epoch(X, y ):\n",
    "  assert len(X) == len(y)\n",
    "  for i ,data in enumerate(X):\n",
    "    # Get generated data from generator\n",
    "\n",
    "    x = data\n",
    "    x_90 = rotate_img(x, 90)\n",
    "    x_180 = rotate_img(x, 180)\n",
    "    x_270 = rotate_img(x, 270)\n",
    "    new_image = np.vstack(x, x_90, x_180, x_270)\n",
    "\n",
    "# train_data_gen = get_data_generator(X_train, y_train)\n",
    "# test_data_gen = get_data_generator(X_test, y_test)\n",
    "\n",
    "# print(model.evaluate_generator(train_data_gen))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMaRRSBl1ywQSy88Gjbnb6u",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Discriminator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python39464bit685e0758a94c4aee86746fae8254c9da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
